---
title: "R Notebook"
output:
  html_notebook: default
  html_document: default
---
The first step involves setting the working directory and importing the required libraries
```{r}
#install.packages("ff")
LibImport <- function(path)
{
  setwd(path)
  #library("ff")
  library(ggplot2)
  library(caret)
  
  load.libraries <- c('data.table', 'testthat', 'gridExtra', 'corrplot', 'GGally', 'ggplot2', 'e1071', 'dplyr','Hmisc')
  install.lib <- load.libraries[!load.libraries %in% installed.packages()]
  for(libs in install.lib) install.packages(libs, dependences = TRUE)
  sapply(load.libraries, require, character = TRUE)
}
```

Calling the Library Import Function: - 
```{r}
path.var = "C:/Users/LEON/Desktop/Ds Udemy/House_Pred"
LibImport(path.var)
```

Creating a function to count features with missing values and to plot a visual of them.
```{r}
PlotMissing <- function(full.dat)
{
    num_na <- sort(colSums(is.na(full.dat)), decreasing = TRUE)
    num_na <- num_na[num_na>0]
    
    ggplot()+ geom_bar(aes(x=reorder(names(num_na),num_na), y= num_na),stat = 'identity')+xlab("Variables with Missing Values")+ylab("Number of missing values")+coord_flip()
}
```


```{r}
test_data <- read.csv("test.csv")
train_data <- read.csv("train.csv")
summary(test_data)

target_variable <- train_data$SalePrice

full <- rbind(train_data[,1:80],test_data)

PlotMissing(full)
```

The next step is to explore these features and determine the percentage of missing values for each of them to decide whether to drop them or impute the missing values.
```{r}
summary(full$PoolQC)
summary(full$MiscFeature)
summary(full$Alley)
summary(full$Fence)
summary(full$FireplaceQu)
summary(full$LotFrontage)
```

```{r}
ExtractColTypes <- function(train_data)
{
  cat_var <- names(train_data)[which(sapply(train_data, is.factor))]
  cat_car <- c(cat_var, 'BedroomAbvGr', 'HalfBath', ' KitchenAbvGr','BsmtFullBath', 'BsmtHalfBath', 'MSSubClass')
  numeric_var <- names(train_data)[which(sapply(train_data, is.numeric))]

  return(list(v1=cat_var,v2=cat_car,v3=numeric_var))
  }

list_types <- ExtractColTypes(train_data)

cat_var <- list_types$v1
cat_car <- list_types$v2
numeric_var <- list_types$v3
```


The next step involves plotting a correlation matrix for the numeric variables. We create a function for reusability.
```{r}
PlotCorMat <- function(df,num_var)
{
cor_matx <- round(cor(na.omit(df[,names(df)%in%num_var])),2)

corrplot(corr = cor_matx, method = "circle",type='lower',title = "Correlation plot of Numeric Variables",addCoefasPercent=TRUE,order = "FPC",tl.cex = 0.6,tl.srt = 45,tl.col ='black')
}
```

Creating the Correlation Map for the entire dataset excluding the Target Variable.
```{r}
PlotCorMat(full,numeric_var)
```

Calculating the percentage of missing values for each feature having NA's
```{r}
list_na_vars = c('PoolQC','MiscFeature','Alley','Fence','FireplaceQu','LotFrontage','GarageYrBlt','GarageQual','GarageFinish','GarageCond','GarageType')
na_values <- as.list(NULL)
na_values <- colSums(is.na(full[,list_na_vars]))
na_percs <- lapply(na_values, FUN = function(x){((x/2919)*100)})
df.na_percs <- as.data.frame(na_percs)
na_values <- as.data.frame(na_values)
na_values
df.na_percs
```


Imputing the missing values for the missing values or deciding to drop or keep features.
```{r}
summary(full$LotFrontage)
full$LotFrontage[which(is.na(full$LotFrontage))] <- 68
summary(full$LotFrontage)

summary(full$FireplaceQu)
summary(full$Fireplaces)
ggplot(full, aes(x=full$FireplaceQu, y=full$Fireplaces)) + stat_summary(fun.y ="length", geom="bar")

summary(full$GarageYrBlt)
ggplot(full, aes(x=full$GarageType, y=full$GarageCars)) + stat_summary(fun.y ="length", geom="bar")
```

Plotting correations for the training dataset features against the target variable
```{r}
cor_tr <- cbind(train_data[,names(train_data)%in%numeric_var],target_variable)

train_cor_mat <- round(cor(na.omit(cor_tr)),2)
train_cor_mat1 <- rcorr(as.matrix(cor_tr))

flattenCorrMatrix <- function(cormat, pmat) {
  ut <- upper.tri(cormat)
  data.frame(
    row = rownames(cormat)[row(cormat)[ut]],
    column = rownames(cormat)[col(cormat)[ut]],
    cor  =(cormat)[ut],
    p = pmat[ut]
  )
}

flat_cor_mat <- flattenCorrMatrix(train_cor_mat1$r, train_cor_mat1$P)
flat_cor_mat <- filter(flat_cor_mat,flat_cor_mat$cor>0.7)

corrplot(corr = train_cor_mat, method = "circle",type = 'lower',order = 'FPC',title = "Correlation plot of Training Numeric Variables and Target Variable",tl.col = "black",tl.cex = 0.6,tl.offset=0.5 ,tl.srt = 45,diag=TRUE)

flat_cor_mat
```

